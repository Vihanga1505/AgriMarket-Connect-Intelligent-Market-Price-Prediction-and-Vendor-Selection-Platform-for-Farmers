{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dPpT4AmxBuI1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Data Preprocessing\n",
        "def preprocess_data(df):\n",
        "    # Convert date to datetime\n",
        "    df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "    # Extract features from date\n",
        "    df['Year'] = df['Date'].dt.year\n",
        "    df['Month'] = df['Date'].dt.month\n",
        "    df['Day'] = df['Date'].dt.day\n",
        "    df['DayOfWeek'] = df['Date'].dt.dayofweek\n",
        "    # Encode vegetable names\n",
        "    vegetable_encoder = LabelEncoder()\n",
        "    df['Vegetable_Encoded'] = vegetable_encoder.fit_transform(df['Vegetable'])\n",
        "\n",
        "    return df, vegetable_encoder"
      ],
      "metadata": {
        "id": "jpQIrC82B-Ss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Prepare sequences for LSTM\n",
        "def create_sequences(X, y, time_steps=5):\n",
        "    Xs, ys = [], []\n",
        "    for i in range(len(X) - time_steps):\n",
        "        Xs.append(X[i:(i + time_steps)])\n",
        "        ys.append(y[i + time_steps])\n",
        "    return np.array(Xs), np.array(ys)"
      ],
      "metadata": {
        "id": "uIQGUMt7DBti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Build Hybrid Model Class\n",
        "class HybridPricePredictor:\n",
        "    def __init__(self, time_steps=5, lstm_units=64):\n",
        "        self.time_steps = time_steps\n",
        "        self.lstm_units = lstm_units\n",
        "        self.scaler = StandardScaler()\n",
        "        self.rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "        self.lstm_model = None\n",
        "        self.vegetable_encoder = None\n",
        "\n",
        "    def build_lstm_model(self, input_shape):\n",
        "        model = Sequential([\n",
        "            LSTM(self.lstm_units, return_sequences=True, input_shape=input_shape),\n",
        "            Dropout(0.2),\n",
        "            LSTM(self.lstm_units//2),\n",
        "            Dropout(0.2),\n",
        "            Dense(32, activation='relu'),\n",
        "            Dense(1)\n",
        "        ])\n",
        "        model.compile(optimizer='adam', loss='mse')\n",
        "        return model\n",
        "\n",
        "    def fit(self, df):\n",
        "        # Preprocess data\n",
        "        processed_df, self.vegetable_encoder = preprocess_data(df)\n",
        "\n",
        "        # Features and target\n",
        "        features = ['Year', 'Month', 'Day', 'DayOfWeek', 'Vegetable_Encoded']\n",
        "        X = processed_df[features].values\n",
        "        y = processed_df['Price'].values\n",
        "\n",
        "        # Scale features\n",
        "        X_scaled = self.scaler.fit_transform(X)\n",
        "\n",
        "        # Create sequences for LSTM\n",
        "        X_seq, y_seq = create_sequences(X_scaled, y, self.time_steps)\n",
        "\n",
        "        # Split data\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)\n",
        "\n",
        "        # Train LSTM\n",
        "        self.lstm_model = self.build_lstm_model((self.time_steps, X_train.shape[2]))\n",
        "        history = self.lstm_model.fit(X_train, y_train, epochs=20, batch_size=32,\n",
        "                                    validation_split=0.1, verbose=1)\n",
        "\n",
        "        # Get LSTM features\n",
        "        lstm_features_train = self.lstm_model.predict(X_train)\n",
        "        lstm_features_test = self.lstm_model.predict(X_test)\n",
        "\n",
        "        # Combine original features with LSTM features for RF\n",
        "        X_train_rf = np.hstack((X_train[:, -1, :], lstm_features_train))\n",
        "        X_test_rf = np.hstack((X_test[:, -1, :], lstm_features_test))\n",
        "\n",
        "        # Train Random Forest\n",
        "        self.rf_model.fit(X_train_rf, y_train)\n",
        "\n",
        "        # Evaluate\n",
        "        y_pred = self.rf_model.predict(X_test_rf)\n",
        "        self.evaluate(y_test, y_pred)\n",
        "\n",
        "        return history\n",
        "\n",
        "    def predict(self, date, vegetable):\n",
        "        # Prepare input\n",
        "        date = pd.to_datetime(date)\n",
        "        input_df = pd.DataFrame({\n",
        "            'Date': [date],\n",
        "            'Vegetable': [vegetable]\n",
        "        })\n",
        "\n",
        "        # Preprocess input\n",
        "        input_df, _ = preprocess_data(input_df)\n",
        "        features = ['Year', 'Month', 'Day', 'DayOfWeek', 'Vegetable_Encoded']\n",
        "        X = input_df[features].values\n",
        "\n",
        "        # Scale features\n",
        "        X_scaled = self.scaler.transform(X)\n",
        "\n",
        "        # Create sequence (padding with zeros for single prediction)\n",
        "        X_seq = np.zeros((1, self.time_steps, X_scaled.shape[1]))\n",
        "        X_seq[0, -1, :] = X_scaled\n",
        "\n",
        "        # Get LSTM features\n",
        "        lstm_features = self.lstm_model.predict(X_seq)\n",
        "\n",
        "        # Combine features for RF\n",
        "        X_rf = np.hstack((X_scaled, lstm_features))\n",
        "\n",
        "        # Predict\n",
        "        prediction = self.rf_model.predict(X_rf)\n",
        "        return prediction[0]\n",
        "\n",
        "    def evaluate(self, y_true, y_pred):\n",
        "        rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "        mae = mean_absolute_error(y_true, y_pred)\n",
        "        r2 = r2_score(y_true, y_pred)\n",
        "\n",
        "        print(f\"RMSE: {rmse:.4f}\")\n",
        "        print(f\"MAE: {mae:.4f}\")\n",
        "        print(f\"R2 Score: {r2:.4f}\")\n",
        "\n",
        "        return rmse, mae, r2"
      ],
      "metadata": {
        "id": "9nuzxE5WDJPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Load your data\n",
        "    df = pd.read_csv('/content/drive/MyDrive/FYPDATA.csv')\n",
        "\n",
        "    # Initialize and train model\n",
        "    model = HybridPricePredictor(time_steps=5)\n",
        "    history = model.fit(df)\n",
        "\n",
        "    # Example prediction\n",
        "    date = \"2026-08-22\"\n",
        "    vegetable = \"Strawberries\"\n",
        "    predicted_price = model.predict(date, vegetable)\n",
        "    print(f\"Predicted price for {vegetable} on {date}: ${predicted_price:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scHIuJ3rDQSi",
        "outputId": "a581f361-e0b2-42d0-dbcf-6ba1018d96ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - loss: 0.3033 - val_loss: 0.2254\n",
            "Epoch 2/20\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.2177 - val_loss: 0.2249\n",
            "Epoch 3/20\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.2142 - val_loss: 0.2240\n",
            "Epoch 4/20\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.2095 - val_loss: 0.2211\n",
            "Epoch 5/20\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.2033 - val_loss: 0.2230\n",
            "Epoch 6/20\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.2206 - val_loss: 0.2200\n",
            "Epoch 7/20\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.2182 - val_loss: 0.2159\n",
            "Epoch 8/20\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.2011 - val_loss: 0.2168\n",
            "Epoch 9/20\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.2018 - val_loss: 0.2146\n",
            "Epoch 10/20\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.2030 - val_loss: 0.2089\n",
            "Epoch 11/20\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.1962 - val_loss: 0.2051\n",
            "Epoch 12/20\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.2048 - val_loss: 0.2048\n",
            "Epoch 13/20\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.2013 - val_loss: 0.2036\n",
            "Epoch 14/20\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.2059 - val_loss: 0.2001\n",
            "Epoch 15/20\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.2096 - val_loss: 0.2005\n",
            "Epoch 16/20\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.1996 - val_loss: 0.2002\n",
            "Epoch 17/20\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.1982 - val_loss: 0.1996\n",
            "Epoch 18/20\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.2013 - val_loss: 0.1967\n",
            "Epoch 19/20\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.1876 - val_loss: 0.1934\n",
            "Epoch 20/20\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.1908 - val_loss: 0.1961\n",
            "\u001b[1m394/394\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "RMSE: 0.4055\n",
            "MAE: 0.2746\n",
            "R2 Score: 0.2731\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
            "Predicted price for Strawberries on 2026-08-22: $0.78\n"
          ]
        }
      ]
    }
  ]
}